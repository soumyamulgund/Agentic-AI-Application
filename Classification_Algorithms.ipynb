{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyamulgund/Agentic-AI-Application/blob/main/Classification_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiA3IfN3-6tu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification, make_blobs\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper: Decision Boundary Plot"
      ],
      "metadata": {
        "id": "hcSIbmAd_oUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model, X, y, title):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(x_min, x_max, 300),\n",
        "        np.linspace(y_min, y_max, 300)\n",
        "    )\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "V7AoVAg4-7UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dummy 2D classification data"
      ],
      "metadata": {
        "id": "_-BToDPY_kAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#General Purpose(Not Linearly Seperable)"
      ],
      "metadata": {
        "id": "GXSnC_nSpHS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=200,\n",
        "    n_features=2,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    class_sep=1.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c=y, edgecolors='k')\n",
        "plt.title(\"Non Linearly Separable Dataset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ESpn4Ak-7R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Strictly Linearly Seperable"
      ],
      "metadata": {
        "id": "9dAyC5zkpOHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_lin, y_lin = make_blobs(\n",
        "    n_samples=200,\n",
        "    centers=2,\n",
        "    n_features=2,\n",
        "    cluster_std=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "plt.scatter(X_lin[:,0], X_lin[:,1], c=y_lin, edgecolors='k')\n",
        "plt.title(\"Linearly Separable Dataset (Perceptron & SVM)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ihnyTubcn6uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "g_YOiy6z_rxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(logreg, X, y, \"Logistic Regression\")\n"
      ],
      "metadata": {
        "id": "hxdn6keY-7Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perceptron — FROM SCRATCH"
      ],
      "metadata": {
        "id": "MOJ22Z29_xN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerceptronScratch:\n",
        "    def __init__(self, lr=0.1):\n",
        "        self.lr = lr\n",
        "\n",
        "    def fit(self, X, y, epochs=1):\n",
        "        if not hasattr(self, \"w\"):\n",
        "            self.w = np.zeros(X.shape[1])\n",
        "            self.b = 0\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            for xi, yi in zip(X, y):\n",
        "                yi = 1 if yi == 1 else -1\n",
        "                if yi * (np.dot(xi, self.w) + self.b) <= 0:\n",
        "                    self.w += self.lr * yi * xi\n",
        "                    self.b += self.lr * yi\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (np.dot(X, self.w) + self.b >= 0).astype(int)\n"
      ],
      "metadata": {
        "id": "5aInmSl3-7Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Movement of Decision Boundary"
      ],
      "metadata": {
        "id": "eM7ILm-g_3LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron = PerceptronScratch(lr=0.05)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    perceptron.fit(X_lin, y_lin, epochs=1)\n",
        "    plot_decision_boundary(\n",
        "        perceptron,\n",
        "        X_lin,\n",
        "        y_lin,\n",
        "        f\"Perceptron – Epoch {epoch}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Ukyk4IZp-7ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM (sklearn) + Supporting Hyperplanes"
      ],
      "metadata": {
        "id": "HZcg5598_8ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel=\"linear\", C=1.0)\n",
        "svm.fit(X_lin, y_lin)\n",
        "\n",
        "plot_decision_boundary(\n",
        "    svm,\n",
        "    X_lin,\n",
        "    y_lin,\n",
        "    \"SVM (Linear Kernel, Linearly Separable Data)\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "w0tZZmmE-7e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM SUPPORTING HYPERPLANES"
      ],
      "metadata": {
        "id": "l6JUB1icpril"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = svm.coef_[0]\n",
        "b = svm.intercept_[0]\n",
        "\n",
        "x_vals = np.linspace(X_lin[:, 0].min(), X_lin[:, 0].max(), 200)\n",
        "\n",
        "plt.scatter(X_lin[:, 0], X_lin[:, 1], c=y_lin, edgecolors=\"k\")\n",
        "plt.plot(x_vals, -(w[0]*x_vals + b) / w[1], 'k', label=\"Decision Boundary\")\n",
        "plt.plot(x_vals, -(w[0]*x_vals + b - 1) / w[1], 'k--', label=\"Margin\")\n",
        "plt.plot(x_vals, -(w[0]*x_vals + b + 1) / w[1], 'k--')\n",
        "plt.legend()\n",
        "plt.title(\"SVM with Supporting Hyperplanes\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "W3o4hPXK-7hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#k-NN (sklearn)"
      ],
      "metadata": {
        "id": "IIMorMPDAE3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(knn, X, y, \"k-NN (k=5)\")\n"
      ],
      "metadata": {
        "id": "UpIYH_B2-7kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree (sklearn)"
      ],
      "metadata": {
        "id": "8QnZKXPCAJEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(max_depth=3)\n",
        "tree.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(tree, X, y, \"Decision Tree\")\n"
      ],
      "metadata": {
        "id": "f_25ZhvO-7m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tree Diagram"
      ],
      "metadata": {
        "id": "VKxvcT7dAQzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plot_tree(tree, filled=True, feature_names=[\"x1\", \"x2\"])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "if9Dv53m_Six"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest (sklearn)"
      ],
      "metadata": {
        "id": "eVYTIYxlAM68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(rf, X, y, \"Random Forest\")\n"
      ],
      "metadata": {
        "id": "__LnUrYK_Uwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Boosted Decision Trees (sklearn)"
      ],
      "metadata": {
        "id": "7jf9_6FQAX2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbdt = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3\n",
        ")\n",
        "gbdt.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(gbdt, X, y, \"Gradient Boosted Trees\")\n"
      ],
      "metadata": {
        "id": "Z88UsAYb_WWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost (sklearn)"
      ],
      "metadata": {
        "id": "3W1PQ2dZTOTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3\n",
        ")\n",
        "xgb_clf.fit(X, y)\n",
        "\n",
        "plot_decision_boundary(xgb_clf, X, y, \"XGBoost\")"
      ],
      "metadata": {
        "id": "jRTyMeeFTL-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Unsupervised Learning***"
      ],
      "metadata": {
        "id": "hFROaULus30F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PCA DATASET"
      ],
      "metadata": {
        "id": "Ic37uTNHtAJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Correlated 2D data\n",
        "X_pca = np.random.multivariate_normal(\n",
        "    mean=[0, 0],\n",
        "    cov=[[3, 2],\n",
        "         [2, 2]],\n",
        "    size=300\n",
        ")\n",
        "\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n",
        "plt.title(\"Original 2D Data (Correlated)\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "s639Kezr_Xza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Applying PCA"
      ],
      "metadata": {
        "id": "G4gZ6xbptEJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize before PCA\n",
        "X_pca_scaled = StandardScaler().fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=1)\n",
        "X_reduced = pca.fit_transform(X_pca_scaled)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "PbKhqJEttCkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize Principal Components"
      ],
      "metadata": {
        "id": "YsrJ_vTptH6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Principal axis\n",
        "pc = pca.components_[0]\n",
        "\n",
        "plt.scatter(X_pca_scaled[:, 0], X_pca_scaled[:, 1], alpha=0.3)\n",
        "\n",
        "# Plot principal direction\n",
        "plt.arrow(\n",
        "    0, 0,\n",
        "    pc[0] * 3, pc[1] * 3,\n",
        "    color='r', width=0.02\n",
        ")\n",
        "\n",
        "plt.title(\"PCA: Principal Component Direction\")\n",
        "plt.xlabel(\"x1\")\n",
        "plt.ylabel(\"x2\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Sz3S2vutFn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PCA (2D → 1D → BACK TO 2D)"
      ],
      "metadata": {
        "id": "0pkt9l0atvaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=1)\n",
        "X_pca_1d = pca.fit_transform(X_pca_scaled)\n",
        "\n",
        "# Reconstruct back to 2D\n",
        "X_reconstructed = pca.inverse_transform(X_pca_1d)\n"
      ],
      "metadata": {
        "id": "HjE7JO3HtzUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(\n",
        "    X_pca_scaled[:, 0], X_pca_scaled[:, 1],\n",
        "    alpha=0.3, label=\"Original\"\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    X_reconstructed[:, 0], X_reconstructed[:, 1],\n",
        "    alpha=0.6, label=\"Reconstructed\"\n",
        ")\n",
        "\n",
        "plt.legend()\n",
        "plt.title(\"PCA Reconstruction (1D → 2D)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1huWOYext2CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# High-dimensional correlated data\n",
        "X_hd, _ = make_classification(\n",
        "    n_samples=500,\n",
        "    n_features=20,\n",
        "    n_informative=8,\n",
        "    n_redundant=12,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Standardize\n",
        "X_hd_scaled = StandardScaler().fit_transform(X_hd)\n"
      ],
      "metadata": {
        "id": "sgkPiSmioaGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(X_hd_scaled)\n",
        "\n",
        "explained_var = pca.explained_variance_ratio_\n",
        "cumulative_var = np.cumsum(explained_var)\n"
      ],
      "metadata": {
        "id": "J5mFTUyXpUnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(\n",
        "    range(1, len(cumulative_var) + 1),\n",
        "    cumulative_var,\n",
        "    marker='o',\n",
        "    label=\"Cumulative Variance\"\n",
        ")\n",
        "\n",
        "plt.axhline(0.85, color='r', linestyle='--', label='85% threshold')\n",
        "plt.axhline(0.95, color='g', linestyle='--', label='95% threshold')\n",
        "\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Cumulative Variance Explained\")\n",
        "plt.title(\"Choosing the Number of PCA Components\")\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wzha7AKkpWpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_85 = np.argmax(cumulative_var >= 0.85) + 1\n",
        "n_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
        "\n",
        "print(f\"Components for 85% variance: {n_85}\")\n",
        "print(f\"Components for 95% variance: {n_95}\")\n"
      ],
      "metadata": {
        "id": "0uoLX8RupYzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clustering Dataset"
      ],
      "metadata": {
        "id": "14Z7_arhtN7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X_cluster, _ = make_blobs(\n",
        "    n_samples=300,\n",
        "    centers=3,\n",
        "    cluster_std=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "plt.scatter(X_cluster[:, 0], X_cluster[:, 1])\n",
        "plt.title(\"Unlabeled Data for Clustering\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0UTKZ8MltMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Apply K-Means"
      ],
      "metadata": {
        "id": "NDb4AU5JtTEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "labels = kmeans.fit_predict(X_cluster)\n"
      ],
      "metadata": {
        "id": "u-gWnlcqtRdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VISUALIZE CLUSTERS & CENTROIDS"
      ],
      "metadata": {
        "id": "Elt9sbtjtYyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_cluster[:, 0], X_cluster[:, 1], c=labels, cmap='viridis')\n",
        "plt.scatter(\n",
        "    kmeans.cluster_centers_[:, 0],\n",
        "    kmeans.cluster_centers_[:, 1],\n",
        "    s=200,\n",
        "    c='red',\n",
        "    marker='X'\n",
        ")\n",
        "plt.title(\"K-Means Clustering (k=3)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "97igxqIVtU0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Elbow Method"
      ],
      "metadata": {
        "id": "9eDCVuQktn22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertia = []\n",
        "\n",
        "K_range = range(1, 10)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_cluster)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.plot(K_range, inertia, marker='o')\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia (Within-cluster SSE)\")\n",
        "plt.title(\"Elbow Method for K-Means\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rdgSGibctc0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQn77py0tpus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}